{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c85568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.txt\", sep=\";\", header=None, names=[\"text\", \"emotions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5930b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed0b61",
   "metadata": {},
   "source": [
    "# data cleaning and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a789b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f899f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"emotions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ae716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert emotions to numbers\n",
    "\n",
    "unique_emotions = df[\"emotions\"].unique()\n",
    "emotion_numbers = {}\n",
    "# Assign a unique number to each emotion\n",
    "i = 0\n",
    "for emotion in unique_emotions:\n",
    "    emotion_numbers[emotion] = i\n",
    "    i += 1\n",
    "\n",
    "df[\"emotions\"] = df[\"emotions\"].map(emotion_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all text to lower case\n",
    "df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90792457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation\n",
    "import string\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ba111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers from text\n",
    "def remove_numbers(text):\n",
    "    new = \"\"\n",
    "    for i in text:\n",
    "        if not i.isdigit():\n",
    "            new += i\n",
    "    return new\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7efe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing urls/links from text\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67185a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing extra spaces from text\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_extra_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d61cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing emojis from text\n",
    "def remove_emojis(text):\n",
    "    new = \"\"\n",
    "    for i in text:\n",
    "        if i.isascii():\n",
    "            new += i\n",
    "    return new\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68481eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a397c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords using nltk library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf53e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd045ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b996021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenzing and removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_text = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in eng_stopwords:\n",
    "            cleaned_text.append(word)\n",
    "\n",
    "    # Join the cleaned words back into a single string\n",
    "    return \" \".join(cleaned_text)\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14476f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating features and labels\n",
    "x = df[\"text\"]\n",
    "y = df[\"emotions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b91d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa8ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3f466cc",
   "metadata": {},
   "source": [
    "## model training using bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d075fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_model = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "lr_model.fit(X_train_bow, y_train)\n",
    "y_pred = lr_model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Logistic Regression model: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06865c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import joblib\n",
    "joblib.dump(lr_model, \"logistic_regression_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26030a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
